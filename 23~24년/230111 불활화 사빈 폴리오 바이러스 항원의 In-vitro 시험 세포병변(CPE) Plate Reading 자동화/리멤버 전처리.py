# -*- coding: utf-8 -*-
"""CPE_Rev.01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dgp0JggtAL6UaEz9UuVWhsKuaELfA-1S

# Install the necessary packages

# Import Packages
"""

from imutils.perspective import four_point_transform
from imutils.contours import sort_contours
import matplotlib.pyplot as plt
import imutils
import cv2
import re
import requests
import numpy as np

"""## Function to display images in Jupyter Notebooks and Google Colab
Colab에서 이미지를 확인하기위한 Function
"""

def plt_imshow(title='image', img=None, figsize=(8 ,5)):
    plt.figure(figsize=figsize)

    if type(img) == list:
        if type(title) == list:
            titles = title
        else:
            titles = []

            for i in range(len(img)):
                titles.append(title)

        for i in range(len(img)):
            if len(img[i].shape) <= 2:
                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)
            else:
                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)

            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)
            plt.title(titles[i])
            plt.xticks([]), plt.yticks([])

        plt.show()
    else:
        if len(img.shape) < 3:
            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        else:
            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.imshow(rgbImg)
        plt.title(title)
        plt.xticks([]), plt.yticks([])
        plt.show()

"""# Load Image"""

# CPE 큰거 테두리 포함
url = 'https://drive.google.com/uc?export=view&id=1byoEsn8k0QzMNY0x5_sFmqKSrjJWOu8S'

# CPE 작은거 테두리 포함
url = 'https://drive.google.com/uc?export=view&id=1Rs3P2UIKizPZM2K6rXpp7TzoG-LS4f_C'

# CPE 작은거 밝은 거
url = 'https://drive.google.com/uc?export=view&id=17cT3eN6eZWB4i6ZGQWT5ig01ZK165ZxW'

# CPE 작은거 어두운 거
url = 'https://drive.google.com/uc?export=view&id=1fCdNMomC3965SLyPTBmWdnfC4-bidPzV'

# CPE 큰 거
url = 'https://drive.google.com/uc?export=view&id=1JTsNlEYMwk-GJhBMrsl5w1L0LRJSzbTO'

image_nparray = np.asarray(bytearray(requests.get(url).content), dtype=np.uint8)
org_image = cv2.imdecode(image_nparray, cv2.IMREAD_COLOR)

plt_imshow("orignal image", org_image)

"""## Scan 이미지 변환"""

def make_scan_image(image, width, ksize=(5,5), min_threshold=75, max_threshold=200):
  image_list_title = []
  image_list = []

  org_image = image.copy()
  image = imutils.resize(image, width=width)
  ratio = org_image.shape[1] / float(image.shape[1])

  # 이미지를 grayscale로 변환하고 blur를 적용
  # 모서리를 찾기위한 이미지 연산
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  blurred = cv2.GaussianBlur(gray, ksize, 0)
  edged = cv2.Canny(blurred, min_threshold, max_threshold)

  image_list_title = ['gray', 'blurred', 'edged']
  image_list = [gray, blurred, edged]

  # contours를 찾아 크기순으로 정렬
  cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  cnts = imutils.grab_contours(cnts)
  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)

  findCnt = None

    # Contour란 같은 값을 가진 곳을 연결한 선. 이미지의 외곽선을 검출하기 위해 사용.
    # ```cv2.findContours(image, mode, method, contours=None, hierarchy=None, offset=None) -> contours```
    # • image: 입력 이미지. non-zero 픽셀을 객체로 간주함
    # • mode: 외곽선 검출 모드. cv2.RETR_로 시작하는 상수
    # • method: 외곽선 근사화 방법. cv2.CHAIN_APPROX_로 시작하는 상수

  # 정렬된 contours를 반복문으로 수행하며 4개의 꼭지점을 갖는 도형을 검출
  for c in cnts:
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.02 * peri, True)

    # contours가 크기순으로 정렬되어 있기때문에 제일 첫번째 사각형을 영역으로 판단하고 break
    if len(approx) == 4:
      findCnt = approx
      break


  # 만약 추출한 윤곽이 없을 경우 오류
  if findCnt is None:
    raise Exception(("Could not find outline."))


  output = image.copy()
  cv2.drawContours(output, [findCnt], -1, (0, 255, 0), 2)

  image_list_title.append("Outline")
  image_list.append(output)

  # 원본 이미지에 찾은 윤곽을 기준으로 이미지를 보정
  transform_image = four_point_transform(org_image, findCnt.reshape(4, 2) * ratio)

  plt_imshow(image_list_title, image_list)
  plt_imshow("Transform", transform_image)

  return transform_image

receipt_image = make_scan_image(org_image, width=200, ksize=(5, 5), min_threshold=20, max_threshold=100)

"""## 특정 영역 추출

---
이미지 처리 기술과 OpenCV 라이브러리를 사용하여 입력 이미지에서 원하는 텍스트만 추출

복잡한 구조의 이미지인 경우에는 추출 결과가 좋지 않기 때문에 원하는 영역만 추출하도록 함

본 과제는 약간 정형화된 이미지가 입력되기 때문에
*이미지에서 내가 원하는 영역을 정확하게 파악하고 출력하도록 함*

### 이미지 연산을 통한 영역 추출

* 그레이스케일로 변환
* 노이즈를 줄이기 위해 가우시안 블러 적용
* 흐릿한 Grayscale 이미지에 blackhat 모노폴리 연산을 적용
    * blackhat연산은 밝은 배경(투명한 터브)에서 어두운 영역(염색 부분)을 드러내기 위해 사용
* 닫힘 연산을 통해 끊어져보이는 객체를 연결하여 Grouping합니다.
"""

gray = cv2.cvtColor(receipt_image, cv2.COLOR_BGR2GRAY)
(H, W) = gray.shape

rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 20))
sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 21))

gray = cv2.GaussianBlur(gray, (11, 11), 0)
blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)

grad = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)
grad = np.absolute(grad)
(minVal, maxVal) = (np.min(grad), np.max(grad))
grad = (grad - minVal) / (maxVal - minVal)
grad = (grad * 255).astype("uint8")

grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, rectKernel)
thresh = cv2.threshold(grad, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]

close_thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)
close_thresh = cv2.erode(close_thresh, None, iterations=2)

plt_imshow(["Original", "Blackhat", "Gradient", "Rect Close", "Square Close"], [receipt_image, blackhat, grad, thresh, close_thresh], figsize=(16, 10))

"""### Grouping 이미지 확대"""

plt_imshow(["Square Close"], [close_thresh], figsize=(16, 10))

"""### CPE 사이즈에 맞게 추출

Grouping 된 영역의 윤곽선을 찾고 그 윤곽선이 특정 조건 (Ex. 종횡비 등)에 만족하는 영역만 추출합니다.
"""

cnts = cv2.findContours(close_thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
cnts = sort_contours(cnts, method="top-to-bottom")[0]

roi_list = []
roi_title_list = []

margin = 20
receipt_grouping = receipt_image.copy()

for c in cnts:
  (x, y, w, h) = cv2.boundingRect(c)
  ar = w // float(h)

  if ar > 3.0 and ar < 6.5 and (W/2) < x: # CPE 에 맞게 수정 필요
    color = (0, 255, 0)
    roi = receipt_image[y - margin:y + h + margin, x - margin:x + w + margin]
    roi_list.append(roi)
    roi_title_list.append("Roi_{}".format(len(roi_list)))
  else:
    color = (0, 0, 255)

  cv2.rectangle(receipt_grouping, (x - margin, y - margin), (x + w + margin, y + h + margin), color, 2)
  cv2.putText(receipt_grouping, "".join(str(ar)), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2)

plt_imshow(["Grouping Image"], [receipt_grouping], figsize=(16, 10))

"""찾은 영역을 아래와 같습니다."""

plt_imshow(roi_title_list, roi_list, figsize=(16, 10))

for roi in roi_list:
  gray_roi= cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
  threshold_roi = cv2.threshold(gray_roi, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
  print(threshold_roi)

"""# 이미지 로딩"""

# # EDMS 접사
# image = url_to_image('https://user-images.githubusercontent.com/52515917/226265300-2a6e53db-f6cd-49cc-bef0-cdc0500bc4ec.jpg')

# CPE 큰거 테두리 포함
image = url_to_image('https://drive.google.com/uc?export=view&id=1byoEsn8k0QzMNY0x5_sFmqKSrjJWOu8S')

# # CPE 작은거 테두리 포함
# image = url_to_image('https://drive.google.com/uc?export=view&id=1Rs3P2UIKizPZM2K6rXpp7TzoG-LS4f_C')

# # CPE 작은거 밝은 거
# image = url_to_image('https://drive.google.com/uc?export=view&id=17cT3eN6eZWB4i6ZGQWT5ig01ZK165ZxW')

# # CPE 작은거 어두운 거
# image = url_to_image('https://drive.google.com/uc?export=view&id=1fCdNMomC3965SLyPTBmWdnfC4-bidPzV')

# # CPE 큰 거
# image = url_to_image('https://drive.google.com/uc?export=view&id=1JTsNlEYMwk-GJhBMrsl5w1L0LRJSzbTO')

import cv2
from google.colab.patches import cv2_imshow
import numpy as np
import urllib.request

# 1. url_to_image라는 url에서 이미지를 가져오는 함수를 짜주었다.
# 2. urllib의 urlopen으로 주소를 열어주고
# 3. numpy에서 이미지를 배열로 읽어버린다.
# 4. 이걸 cv2에서 이미지로 읽어버린걸 image에 저장하고
# 5. image를 리턴해준다.
# 6. 이 함수를 링크를 넣어서 실행 해버리는 거다.
# 마지막으로, cv2_imshow를 해버린다.

def url_to_image(url):
  resp = urllib.request.urlopen(url)
  image = np.asarray(bytearray(resp.read()), dtype='uint8')
  image = cv2.imdecode(image, cv2.IMREAD_COLOR)

  return image

cv2_imshow(image)

img = image

"""# Detection 추출
이미지에서 원하는 영역만 추출

# 배지 사이즈에 맞게 자르기 (3 x 2)

# 동그랗게 Segmentation 하기

# 수동으로 관심영역 지정
"""

x=170; y=100; w=100; h=100        # roi 좌표
roi = img[y:y+h, x:x+w]         # roi 지정

print(roi.shape)                # roi shape, (50,50,3)
cv2.rectangle(roi, (0,0), (h-1, w-1), (0,255,0)) # roi 전체에 사각형 그리기 ---②
plt.imshow(img[:,:,(2,1,0)])
plt.xticks([])
plt.yticks([])
plt.show()

# import cv2
# import numpy as np
# from matplotlib import pyplot as plt

hist = cv2.calcHist([img], [0], None, [256], [0, 256])

plt.plot(hist)

plt.show()

# 픽셀의 명암 값이 0인 개수와 255인 픽셀의 개수가 동일

"""# 이미지에 텍스트 삽입. 개별 배지 옆에 밝기 기재 (0 ~ 255)"""



"""문제
- 빛 반사로 인한 밝기 노이즈?
- 복잡하게 Open CV 로 하지 말고, 그냥 YOLO segmentation 적용??
    - 서버에 YOLO PYPI 설치 가능??
"""

