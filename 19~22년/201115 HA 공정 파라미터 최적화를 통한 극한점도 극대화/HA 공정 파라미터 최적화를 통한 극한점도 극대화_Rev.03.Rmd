---
title: "HA 공정 파라미터 최적화를 통한 극한점도 극대화.Rev.03"
output: html_document
---
#
# 1. 분석 목표

a. 엘지 히알루론산나트륨의 극한점도를 극대화할 수 있도록
   HA 생산 공정 파라미터(x) 를 최적화 하고자 함.

b. 극한점도 목표

   평균 : 105% (최근 3개년)

   상승 목표 : 107%

   기준 : 90 ~ 120%

#

# 2. 분석 개요

a. 데이터 : 최근 3개년 엘지히알루론산나트륨(HSB) 생산이력
            (18년 ~ 20년)

b. 변수 : 18ea

   일정하게 고정하는 공정 변수는 제외함
  
   예) Feeding 압력은 1.3bar 로 항상 일정함

c. 공정 : 종배양 ~  흡착

d. 절차 : 
   1) 로지스틱 회귀분석
   2) 의사결정나무

#

# 3. 회귀분석

```{r}
  library(dplyr)
  library(ggplot2)
  library(readxl)
```

```{r}

  raw_HA = read_excel('HA/HSB.xlsx',
                      sheet = 'HSB7',
                      skip = 5)

  HA <- raw_HA

```

### 산점도 확인

균체 제거 시간과 극한 점도와의 상관관계
x : 균체 제거 공정 - 균체 제거 시간(min)
bz : QC 릴리즈 - 극한점도(%)

```{r}
HA_new <- HA %>% select(-a)

  HA_new %>% 
    ggplot(aes(x, bz)) + 
    geom_point(alpha=0.5, color='#A50034') + 
    geom_vline(xintercept=mean(HA_new$x)) +
    geom_hline(yintercept=mean(HA_new$bz))
  
```

### 상관계수 계산

```{r}
cor(HA_new)
```

### 다중 회귀분석에서 변수 선택
단계적 선택법(stepwise selection) 
설명변수를 하나씩 추가하되 무의미한 변수는 제거

```{r}
  lm_HA_all = lm(bz ~., data = HA_new)
  
  lm_HA = step(lm_HA_all, direction= "both")
```

### 최종 step 의 AIC = 201.13
근거 : 회귀모형 단계적 선택법

bz : QC 릴리즈 - 극한점도(%)

m  : 종배양 3 (h)

u  : 균체 제거 공정 - 회수 후 균체제거 전 Holding 시간 (h)

w  : 균체 제거 공정(Holding ~ 균체제거) -  Filter Buffer Tank(TK-HA-125) 온도 조건(℃)

x  : 균체 제거 공정 - 균체 제거 시간(min)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

ao : 한외여과 공정 - 분리모드 전환 후 총 분리시간(h)

bd : 흡착 공정 - 흡착 반응 시간 (h)

```{r}
  lm_HA_best = lm(bz ~ m + u + w + x + y + z + an + ao + bd, data = HA_new)

lm_HA_best
```

### 최종 적합된 모형(회귀식) 확인
극한점도 = 138.36 - m*1.68 - u*1.03 - w*0.50 + x*0.13 + y*0.02 - z*0.03 - an*0.08 + ao*1.73 + bd*1.20

```{r}
  lm_HA_best$coefficients
```

  ### 산점도에 회귀직선 추가
  
종배양 3 공정 소요 시간과 극한 점도와의 회귀직선

m : 종배양 3 공정 - 소용시간 (h)

bz : QC 릴리즈 - 극한점도(%)
  
```{r}
  ggplot(aes(x=m, y=bz), data=HA_new) + 
    geom_point(alpha=0.5, color='#A50034') + 
    geom_vline(xintercept=mean(HA_new$m)) +
    geom_hline(yintercept=mean(HA_new$bz)) +
    geom_abline(slope=lm_HA_best$coefficients[2], 
                intercept=lm_HA_best$coefficients[1], lwd=2, color='#377EB8')
```

### 모형의 설명력 확인
```{r}
summary(lm_HA_best)
```
극한점도 변화량의 82.6% 를 아래 9가지 변수(m, u, ....., bd)로 설명 가능  
lm_HA_best = lm(bz ~ m + u + w + x + y + z + an + ao + bd, data = HA_new

### predict() 를 활용한 예측
각 변수별로 5가지 값(사분위수)을 대입할 때 예측되는 극한점도의 값을 구함

```{r}

  test = read_excel('HA/HSB.xlsx',
                      sheet = 'test',
                      skip = 96)

  test_predict <- as.data.frame(test) %>% 
    select(m, u, w, x, y, z, an, ao, bd)
  
  str(test_predict)

  predict(lm_HA_best, test_predict)
  
```

### 예측 데이터와 예측값 결합

```{r}
test_predict %>% 
  mutate(predict_viscosity = predict(lm_HA_best, test_predict))
```

m  : 종배양 3 공정 - 소요시간 (h)

u  : 균체 제거 공정 - 회수 후 균체제거 전 Holding 시간 (h)

w  : 균체 제거 공정(Holding ~ 균체제거) -  Filter Buffer Tank(TK-HA-125) 온도 조건(℃)

x  : 균체 제거 공정 - 균체 제거 시간(min)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

ao : 한외여과 공정 - 분리모드 전환 후 총 분리시간(h)

bd : 흡착 공정 - 흡착 반응 시간 (h)



# 4. 의사결정나무

### 의사결정 나무 모형 적합 및 시각화
관심변수 : HA 원액의 극한점도 (수치형 변수)

기본 모형 (↓)
```{r}
  library(rpart)
  library(rattle)

  tree_HA = rpart(bz ~ .-a, data=HA)
  
  fancyRpartPlot(tree_HA, tweak=1.0)
```

### 모형 파라미터 변경  

- cp : 비용 복잡도 모수 / 작을 수록 더 분할
- maxdepth : 최다 분할 회수
- minsplit : 분할을 위한 최소 관측치 개수 / 적어도 20개는 있어야 분할
- minbucket: 분할 이후 최소 관측치 개수

최다 분할 회수 3으로 제한(↓)

```{r}

  tree_HA_depth = rpart(bz ~ .-a, data=HA, cp=0.005, maxdepth=3)
  tree_HA_depth
  
  fancyRpartPlot(tree_HA_depth, tweak=1.0)
    
```

- 실제 모형에 등장하지 않아도 대체(surrogate)에 대한 중요도가 계산됨
- maxsurrogate : 대체 조건 개수 / 0으로 지정하면 속도 향상
- 일반적으로 수준의 개수가 많은 범주형 변수가 중요도가 높은 경향이 있음

대체 조건 개수 0 설정(↓)

```{r}

  tree_HA_surro = rpart(bz ~ .-a, data=HA, cp=0.005, maxsurrogate=0)
  tree_HA_surro

  fancyRpartPlot(tree_HA_surro, tweak=1.0)
```

### 변수 중요도 확인

```{r}
  varimp_HA = tree_HA$variable.importance

  df_varimp_HA = data.frame(variable = names(varimp_HA),
                            improvement = varimp_HA) %>% 
    mutate(relative_importance = improvement / sum(improvement))
  df_varimp_HA

  df_varimp_HA %>% 
    ggplot(aes(reorder(variable, relative_importance), relative_importance)) +
    geom_col() + 
    coord_flip()
```

#

극한점도 모형에 큰 영향을 미치는 변수 : 

x  : 균체 제거 공정 - 균체 제거 시간(min)

ao : 한외여과 공정 - 분리모드 전환 후 총 분리시간(h)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

m  : 종배양 3 공정 - 소요 시간 (h)

r  : 본배양 공정 - 본배양액 무게(kg)

s  : 본배양 공정 - 본배양 소요 시간(h)

ak : 한외여과 공정 - UF Tank(132)로 이송된 공정액 부피(L)

w  : 균체 제거 공정(Holding ~ 균체제거) -  Filter Buffer Tank(TK-HA-125) 온도 조건(℃)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

bd : 흡착 공정 - 흡착 반응 시간 (h)

u : 균체 제거 공정 - 회수 후 균체 제거 전 Holding Time (h)

bq : 침전 공정 - 침전, 세척, 하드닝에 사용된 에탄올 양(kg)

be : 흡착 공정 - 흡착제 제거 후 부피 (L)

ㅣ : 종배양 3 공정 - 포도당 농도(g/L)


### 대체 조건 확인

- 변수 중요도로 모든 것을 판단할 수는 없음
- 일반적으로 수준의 개수가 많은 범주형 변수가 중요도가 높은 경향이 있음
- 실제 모형에 등장하지 않아도 대체(surrogate) 에 대한 중요도가 계산됨

```{r}
summary(tree_HA)

```


### 실제 모형에 등장한 변수로만 변수 중요도 계산

- maxsurrogate=0 으로 지정된 모형

```{r}
  varimp_HA_surro = tree_HA_surro$variable.importance

  df_varimp_HA_surro = data.frame(variable = names(varimp_HA_surro),
                                  improvement = varimp_HA_surro) %>% 
      mutate(relative_importance = improvement / sum(improvement))

  df_varimp_HA_surro %>% 
    ggplot(aes(reorder(variable, relative_importance), relative_importance)) +
    geom_col() + 
    coord_flip()

```


극한점도 모형에 큰 영향을 미치는 변수 : 
(surrogate 0 설정시)

x  : 균체 제거 공정 - 균체 제거 시간(min)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

bd : 흡착 공정 - 흡착 반응 시간 (h)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)


### 예측

Train 데이터로 실제 값(Y)과 예측 값(Y)의 차이를 확인함(↓)

```{r}

  predict(tree_HA, HA)
  
```

데이터의 사분위 값으로 극한점도(Y)를 예측함(↓)

```{r}
  test_tree_quan = read_excel('HA/HSB.xlsx',
                      sheet = 'test_tree_quan',
                      skip = 95)
  
  df_test_tree_quan <- as.data.frame(test_tree_quan)
  
  predict(tree_HA, df_test_tree_quan)
```

<!-- 변수 a 에 HSB20001 대신 최소값, 1사분위, 숫자, 공란으로 두면 오류 나옴 -->

# 5. Ridge & LASSO

### 검정 MSE 가 최소가 되는 최적(Optimization) 모델

- Ridge : 산등성이, 능형(Ridge) 회귀

- LASSO : Least Absolute Shrinkage and Selection Operator

- 검정오차(또는 검정MSE)가 최소인 모델을 찾기 위해 능형회귀와 LASSO 모델을 활용함. 

- 기존의 다중회귀모델을 개선하여 편향(bias)과 분산(variance)사이의 최적점을 찾아줌.

- Ridge, Lasso 는 전체 모형의 설명력을 높이기 위해 사용함

```{r}
library(ISLR); library(glmnet) 
```

- 데이터 불러오기 (↓)

```{r}

Rid_HA_x = read_excel('HA/HSB.xlsx',
                      sheet = 'HSB_x',
                      skip = 6,
                      col_names = F)

str(Rid_HA_x)

Rid_HA_y = read_excel('HA/HSB.xlsx',
                      sheet = 'HSB_y',
                      skip = 6,
                      col_names = F)

str(Rid_HA_y)

x = as.matrix(Rid_HA_x)
y = as.matrix(Rid_HA_y)

```

<!-- data.frame 말고 matrix 로 변환해야 함 -->
<!-- 변수 이름(첫 행)은 제거해야 함. 변수 이름 있으면 에러 남 -->
<!-- 데이터 x에서 배치 이름(첫 번째 열) 있으면 에러 남. 전부 numeric 이어야 함 -->

- 0.01에서 10^10범위내 임의의 lambda 100개 생성 후, Ridge 모델 생성 (↓)

```{r}

grid = 10^seq(10, -2, length=100) 
ridge.mod = glmnet(x, y, alpha=0, lambda=grid) 

```

- Ridge 회귀 결과값 확인 (↓)
```{r}
dim(coef (ridge.mod))

```

- 50번째 tuning parameter 인 lambda 값을 확인 (↓)
```{r}
ridge.mod$lambda[50]

```

- 50번째 lambda 값의 회귀계수 확인 (↓)
```{r}
coef(ridge.mod)[,50] 
```

- Lambda 값이 50일 때의 회귀계수 확인 (↓)
```{r}
predict(ridge.mod, s=50, type="coefficients")[1:17,]
```

### train / test set 확보
- data 를 train 과 test set 으로 분리(↓)

```{r}
set.seed(9876) 
train = sample(1:89, 50)
test = (-train)
y.test = y[test]
```

### 검증
- train과 ridge모델을 만들고, test set으로 검증

- Ridge 모델 수립 (↓)
```{r}
ridge.mod = glmnet( x[train,], y[train], alpha=0, lambda=grid, thresh=1e-12)
```

- 예측 (↓)
```{r}
ridge.pred = predict( ridge.mod, s=4, newx=x[test, ] )
```
 
 - SSE / MSE 확인 (↓)
```{r}
difference = ridge.pred - y.test
difference^2
mean(difference^2)
```
 
### 최적 lambda값 계산
- cv.glmnet 함수 이용 최적 lambda 값 계산 (↓)
 
```{r}
set.seed(9876)
cv.out = cv.glmnet(x[train,], y[train], alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam 
```
 
### 회귀계수 예측
- 최적 lambda 값 이용 회귀계수 예측 (↓)
 
```{r}
out = glmnet(x, y, alpha = 0)
predict (out, newx=x[test,], s=bestlam) 
```

# 6. LASSO
- 0.01에서 10^10범위내 임의의 lambda 100개 생성 후, LASSO 모델 생성 (↓)

```{r}

grid = 10^seq(10, -2, length=100) 
lasso.mod = glmnet(x, y, alpha=1, lambda=grid) 

```

- Ridge 회귀 결과값 확인 (↓)
```{r}
dim(coef (lasso.mod))

```

- 50번째 tuning parameter 인 lambda 값을 확인 (↓)
```{r}
lasso.mod$lambda[50]

```

- 50번째 lambda 값의 회귀계수 확인 (↓)
```{r}
coef(lasso.mod)[,50] 
```

- Lambda 값이 50일 때의 회귀계수 확인 (↓)
```{r}
predict(lasso.mod, s=50, type="coefficients")[1:17,]
```

### train / test set 확보
- data 를 train 과 test set 으로 분리(↓)

```{r}
set.seed(9876) 
train = sample(1:89, 50)
test = (-train)
y.test = y[test]
```

### 검증
- train과 LASSO 모델을 만들고, test set으로 검증

- LASSO 모델 수립 (↓)
```{r}
lasso.mod = glmnet( x[train,], y[train], alpha=1, lambda=grid, thresh=1e-12)
```

- 예측 (↓)
```{r}
lasso.pred = predict( lasso.mod, s=4, newx=x[test, ] )
```
 
 - SSE / MSE 확인 (↓)
```{r}
difference = lasso.pred - y.test
difference^2
mean(difference^2)
```
 
### 최적 lambda값 계산
- cv.glmnet 함수 이용 최적 lambda 값 계산 (↓)
 
```{r}
set.seed(9876)
cv.out.lasso = cv.glmnet(x[train,], y[train], alpha=1)
plot(cv.out.lasso)
bestlam_lasso = cv.out.lasso$lambda.min
bestlam_lasso
```
 
### 회귀계수 예측
- 최적 lambda 값 이용 회귀계수 예측 (↓)
 
```{r}
out_lasso = glmnet(x, y, alpha = 1)
predict (out_lasso, newx=x[test,], s=bestlam_lasso) 
```

#
# 7. PLS{}

### 이론

- 차원 축소법을 통해 인자를 줄일 수 있음
- PLS를 통해 과적합 이슈, 다중공선성을 제거할 수 있음

- PLS 패키지에는 PCR(주성분 회귀) 와 PLSR(부분 최소 제곱법) 이 있음

- Principal Components Regression (PCR, 주성분 회귀)
- PCR : supervised
- 주성분 회귀 (PCR) 는 서로 직교하는 components 를 도출하여 다중 공선성을 제거할 수 있음.

- Patrial Least Squares Regression (PLSR, 부분 최소 제곱법)
- PCR : unsupervised

- 데이터 불러오기 (↓)

```{r}
PLS = read_excel('HA/HSB.xlsx',
                      sheet = 'PLS',
                      skip = 5,
                      col_names = T)

str(PLS)

```

- PLS 패키지 불러오기 (↓)

```{r}
library(pls)
```

- 주성분 회귀 실시
Validation 을 통해 MSE 가 도출됨
```{r}
set.seed(9876)
pcr.fit = pcr(bz~.,data=PLS, scale=TRUE, validation="CV" ) 
summary(pcr.fit)

```

- MSE plot 확인
```{r}
validationplot(pcr.fit, val.type="MSEP")

```


### train / test set 확보
- data 를 train 과 test set 으로 분리(↓)

```{r}
set.seed(9876) 
train2 = sample(1:89, 50)
tet = (-train2)
y.test.pcr = PLS$bz[tet]
```

- 89개 관측치를 전부 다 활용하면 모델이 과적합됨.
- 50개는 Train, 나머지 49개는 Test 로 설정함.
```{r}
PLS[tet,]
```
<!--  Error in tempfile(pattern = "_rs_rdf_", tmpdir = outputFolder, fileext = ".rdf") : temporary name too long -->
<!-- Rmd 에서는 이런 에러 메세지가 나오지만 괜찮음. Knit 하면 정상 출력됨. R 스크립트에서는 에러 메세지 안 나옴.  -->

### train으로 pcr모델 만들고, test set으로 검증

- 주성분 회귀실시
```{r}
pcr(bz~., data=PLS, subset=train2, scale=T, validation="CV")

```

- MSE plot 확인
```{r}
validationplot(pcr.fit, val.type="MSEP")

```
- 예측값 계산
- ncomp = 7 로 제한할 경우
```{r}
pcr.pred = predict(pcr.fit, PLS[tet,], ncomp=7) 
```

- MSE계산 (ncomp = 7)
```{r}
mean((pcr.pred-y.test.pcr)^2)

```

### ncomp 제한할 경우
- ncomp = 2 로 제한할 경우
```{r}
pcr.pred.2 = predict(pcr.fit, PLS[tet,], ncomp=2)
```

- MSE계산 (ncomp = 2)
```{r}
mean((pcr.pred.2-y.test.pcr)^2)

```
- ncomp = 7 일 때가 MSE 더 낮음

- 잔차 = 회귀식과 실제값의 차이 (y.test - pcr.pred)
```{r}
cbind(y.test.pcr, pcr.pred) %>% head(10)

```

```{r}
pcr.fit = pcr(bz~.,data=PLS,scale=T, ncomp=7)
summary(pcr.fit)

```

#
# 8. PLSR

### 주성분 회귀모델

- 주성분 회귀 실시
```{r}
set.seed(9876)
pls.fit = plsr(bz~.,data=PLS, subset=train2, scale=TRUE, validation="CV" ) 

```

- MSE plot 확인
```{r}
validationplot(pls.fit, val.type="MSEP")

```

### train으로 pls 모델 만들고, test set으로 검증

- 예측값 계산
```{r}
pls.pred.5 = predict(pls.fit, x[tet,], ncomp=5) 
```

- MSE계산 (ncomp = 5)
```{r}
mean(pls.pred.5-y.test.pcr)^2

```

```{r}
pls.fit = plsr(bz~.,data=PLS, scale=TRUE, ncomp=5 ) 
summary(pls.fit)
```

#
# 9. 개선 성과

### a. 선택과 집중
   - 다양한 공정 Parameter 중 의미 있는 파라미터와 의미 없는 파라미터를 구분하고

   - 의미 있는 파라미터의 관리에 집중하게 됨
   
### b. 근본 원인 확인
   
   - 다양한 인자들이 종속변수에 얼마나 영향을 미치는지 정량적으로 파악하여 공정에 대한 이해도 증대

   - 그동안 무의미하게 취합해왔던 무수한 데이터와 변수 중에 Y 에 영향을 주는 상관 관계가 있는 유의미한 변수를 찾았음
   
   - 어떤 변수가 공정의 특성을 가장 잘 드러내주는지 확인할 수 있게 됨

### c. 미래 예측

   - 회귀식과 중요 변수를 알고있기 때문에 공정 개선이 가능함

### d. 회귀모형 도출

#### 극한점도 = 138.36 - m*1.68 - u*1.03 - w*0.50 + x*0.13 + y*0.02 - z*0.03 - an*0.08 + ao*1.73 + bd*1.20

m  : 종배양 3 공정 - 소요시간 (h)

u  : 균체 제거 공정 - 회수 후 균체제거 전 Holding 시간 (h)

w  : 균체 제거 공정(Holding ~ 균체제거) -  Filter Buffer Tank(TK-HA-125) 온도 조건(℃)

x  : 균체 제거 공정 - 균체 제거 시간(min)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

ao : 한외여과 공정 - 분리모드 전환 후 총 분리시간(h)

bd : 흡착 공정 - 흡착 반응 시간 (h)

### e. 의사결정나무 분석

#### 극한점도 모형에 큰 영향을 미치는 변수 (surrogate 0) :

x  : 균체 제거 공정 - 균체 제거 시간(min)

y  : 균체 제거 공정 - Recovery(회수) 시간(min)

an : 한외여과 공정 - 순환 시간 흐름 시간 13.5초 이하 도달하기까지 시간 (min)

bd : 흡착 공정 - 흡착 반응 시간 (h)

z  : 균체 제거 공정 - Recovery 정제수 부피 (L)

### f. Ridge, Lasso 분석

#

### g. PCR, PLSR 분석

#

| 이 창을 닫으려면 아무 키나 누르세요...
